<html>
    <head>
        <meta http-equiv="content-type" content="text/html; charset=utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
            <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-89717266-1"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'UA-89717266-1');
        </script>
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
        <link href="https://fonts.googleapis.com/css2?family=Merriweather:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/styles/a11y-dark.min.css">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/highlight.min.js"></script>
        <link href="/css/base.css" rel="stylesheet">

        <title>The Blue Lagoon</title>
    <link href="/css/blog.css" rel="stylesheet"></head>
    <body>
        <div class="content">
        <nav>
            <ul>
                <li><a href="/">Home</a></li>
                <li><a href="/blog">Blog</a></li>
                <li><a href="/feed.xml"><span class="small-caps">RSS</span></a></li>
            </ul> 
        </nav>
        
<article>
    <h1 class="title">The Blue Lagoon</h1>
    <section><h2>The Blue Lagoon</h2><p><em><span class="pull-double">“</span>The Blue Lagoon is a 1980 American ro­mance and ad­ven­ture film di­rected by
Ran­dal Kleiser”</em></p><p>This phrase is stuck in my head. Not be­cause I’m a huge fan of poorly rated
movies, but be­cause it’s a test phrase that Google likes to use to show off its
speech syn­the­sis al­go­rithms. Speech syn­the­sis has kinda been stuck in my head
too.</p></section>
<section><h2>Tacotron Yum</h2><p>Recently, re­searchers at Google pub­lished a pa­per de­scrib­ing a text-to-speech
gen­er­a­tion model called<span class="push-double"></span> <span class="pull-double">“</span>Tacotron”. It uses deep learn­ing to learn how to
gen­er­ate au­dio based on in­put text. Besides catch­ing my at­ten­tion due to the
de­li­cious sound­ing ti­tle, the pa­per in­trigued me be­cause of the prob­lems that
arise when try­ing to syn­the­size speech from text. Current speech syn­the­sis
mod­els in pro­duc­tion rely pri­mar­ily on con­cate­na­tion of pre-recorded words, with
some smooth­ing to make the words flow to­gether more. The prob­lem with this
method is that the length of words and in­to­na­tion are not taken fully into
con­sid­er­a­tion, caus­ing the syn­the­sized au­dio to sound ro­botic and un­nat­ural.</p><p>Synthesizing speech is a non-triv­ial prob­lem, mainly be­cause there is a
lot of in­ter­po­la­tion in­volved. Raw text does not pro­vide a lot of clues for the
tone, in­flec­tion, and ex­pres­sive­ness. The in­flec­tion in ask­ing a ques­tion, such
as<span class="push-double"></span> <span class="pull-double">“</span>It’s your birthay to­day?”, is sig­nif­i­cantly dif­fer­ent from that in a state­ment
such as<span class="push-double"></span> <span class="pull-double">“</span>It’s your birth­day to­day!” In ad­di­tion, in­di­vid­ual voices,
ob­vi­ously, dif­fer by a lot, based on gen­der, na­tion­al­ity, etc. It’s hard to
teach a com­puter to gen­er­al­ize the im­por­tant parts.</p><p>Tacotron takes a dif­fer­ent ap­proach from the cur­rent con­cate­na­tive
meth­ods: it uses an<span class="push-double"></span> <span class="pull-double">“</span>end-to-end” ap­proach, wherein it learns from text/​speech
pairs to de­ter­mine how to di­rectly gen­er­ate the raw spec­tro­gram given an in­put
text. This al­lows for it to in­clude fea­tures such as a nat­ural rhythm of speech,
in­cor­po­rate stress and in­to­na­tion. The strength of a deep learn­ing model is that
it can nat­u­rally in­cor­po­rate fea­tures that may oth­er­wise go over­looked. Since it
learns from record­ings, for ex­am­ple, and uses that to gen­er­ate speech, the
gen­er­ated au­dio also in­cludes mouth-sounds and breath­ing that make the speech
sound more hu­man.</p><p>Speech syn­the­sis is an in­cred­i­bly rel­e­vant ap­pli­ca­tion of com­puter
sci­ence, which is why I found the topic so in­ter­est­ing. Text to speech could be
used to au­to­mat­i­cally gen­er­ate au­dio­books, cre­ate di­a­logue pro­ce­du­rally, and
pro­vide ac­cu­rate ver­bal trans­la­tions. Personal as­sis­tant ap­pli­ca­tions that use a
con­ver­sa­tional in­ter­face would re­quire nat­ural speech syn­the­sis for a more
im­mer­sive user ex­pe­ri­ence.</p></section>
<section><h2>Additional Reading</h2><p>You can read the Tacotron pa­per <a href="https://arxiv.org/abs/1703.10135">here</a> (arxiv
1703.10135).</p><p>You can read about an­other one of Google’s speech syn­the­sis pro­jects, WaveNet,
<a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">here</a> (website)
or <a href="https://arxiv.org/abs/1609.03499">here</a> (paper; arxiv 1609.03499).</p></section>
</article>

        </div>
    </body>
</html>
